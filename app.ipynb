{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgnqh0zEKgeO"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install langchain --quiet\n",
        "!pip install pdf2image --quiet\n",
        "!pip install pdfminer.six --quiet\n",
        "!pip install singlestoredb --quiet\n",
        "!pip install requests --quiet\n",
        "!pip install tiktoken --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pARLqxu4f6Pr"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5RR4gpFgUrB"
      },
      "outputs": [],
      "source": [
        "!pip install unstructured\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJmbRAvNghpg"
      },
      "outputs": [],
      "source": [
        "!pip install pdfminer.six\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9YeUfybgvYq"
      },
      "outputs": [],
      "source": [
        "pip install pi-heif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNfw-5WZg2RP"
      },
      "outputs": [],
      "source": [
        "pip install unstructured_inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvwprFMPhsi2"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y poppler-utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Eu4TOSLkdui"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cz1g4IopKq0W",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from langchain_community.document_loaders import OnlinePDFLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import SingleStoreDB\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Set xAI API key\n",
        "os.environ[\"XAI_API_KEY\"] = \"your-xai-api-key-here\"  # Replace with your actual xAI API key\n",
        "\n",
        "# Function to fetch embeddings from xAI API\n",
        "def get_xai_embeddings(text, api_key=os.getenv(\"XAI_API_KEY\")):\n",
        "    url = \"https://api.x.ai/v1\"  # Replace with the correct xAI embeddings endpoint\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "    payload = {\"text\": text}\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"embeddings\"]\n",
        "\n",
        "# Load PDF file from URL\n",
        "def load_pdf_from_url(url):\n",
        "    loader = OnlinePDFLoader(url)\n",
        "    return loader.load()\n",
        "\n",
        "# Split the PDF text into chunks\n",
        "def split_text(data, chunk_size=2000, chunk_overlap=0):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    return text_splitter.split_documents(data)\n",
        "\n",
        "# Define function for xAI chat completion\n",
        "def chat_with_xai(prompt, api_key=os.getenv(\"xai-nQp8Al83QHaSJrfuvrgnGxWmuDshXjXTtNaF1x0PpKOwYvWFcazCM2hvPCIy8qMT8Jc2e32CxURozfgh\")):\n",
        "    url = \"https://api.x.ai/v1\"  # Replace with the correct xAI chat endpoint\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"model\": \"grok-beta\",  # Replace with the desired xAI model name\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "# Function to use xAI for direct text prediction\n",
        "def xai_predict(prompt, api_key=os.getenv(\"api key\")):\n",
        "    url = \"https://api.xai.com/v1/completions\"  # Replace with the correct xAI endpoint\n",
        "    headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n",
        "    payload = {\n",
        "        \"model\": \"xai-gpt-3.5\",  # Replace with the desired model name\n",
        "        \"prompt\": prompt,\n",
        "        \"temperature\": 0.8,\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    response.raise_for_status()\n",
        "    return response.json()[\"choices\"][0][\"text\"]\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    # Load PDF data\n",
        "    pdf_url = \"https://unctad.org/system/files/official-document/wesp2023_en.pdf\"\n",
        "    data = load_pdf_from_url(pdf_url)\n",
        "\n",
        "    # Check PDF loading\n",
        "    if not data:\n",
        "        print(\"Failed to load the PDF file.\")\n",
        "    else:\n",
        "        print(f\"You have {len(data)} document(s) in your data\")\n",
        "        print(f\"There are {len(data[0].page_content)} characters in your document\")\n",
        "\n",
        "        # Split text into chunks\n",
        "        texts = split_text(data)\n",
        "        print(f\"You have {len(texts)} chunks after splitting.\")\n",
        "\n",
        "        # Generate embeddings for text chunks\n",
        "        embeddings = [get_xai_embeddings(text.page_content) for text in texts]\n",
        "\n",
        "        # Create a vector store in SingleStoreDB\n",
        "        docsearch = SingleStoreDB.from_documents(\n",
        "            texts,\n",
        "            embedding=embeddings,\n",
        "            table_name=\"pdf_wes\",\n",
        "        )\n",
        "\n",
        "        # Query and retrieve documents\n",
        "        query = \"What is Tunisia's GDP growth projected to be?\"\n",
        "        docs = docsearch.similarity_search(query)\n",
        "        if docs:\n",
        "            print(f\"Most relevant document: {docs[0].page_content}\")\n",
        "\n",
        "            # Ask the question using xAI\n",
        "            prompt = f\"The user asked: {query}. The most similar text from the document is: {docs[0].page_content}\"\n",
        "            response = chat_with_xai(prompt)\n",
        "            print(\"Response from xAI Chat Model:\")\n",
        "            print(response)\n",
        "\n",
        "            # Direct text prediction using xAI LLM\n",
        "            llm_prediction = xai_predict(query)\n",
        "            print(\"Prediction from xAI LLM:\")\n",
        "            print(llm_prediction)\n",
        "        else:\n",
        "            print(\"No relevant documents found.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}